{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TalkingData (Kaggle)\n",
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\nguy3409\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages\n",
      "Requirement already satisfied: numpy in c:\\users\\nguy3409\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from lightgbm)\n",
      "Requirement already satisfied: scipy in c:\\users\\nguy3409\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from lightgbm)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nguy3409\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from lightgbm)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = r\"C:\\Users\\nguy3409\\TalkingData-master\"\n",
    "\n",
    "def load_data(data_path=DATA_PATH):\n",
    "    # PATHS TO FILE\n",
    "    train_path = os.path.join(data_path, \"train.csv\")\n",
    "    test_path = os.path.join(data_path, \"test.csv\")\n",
    "    ssize = 50000000\n",
    "    return pd.read_csv(train_path,nrows=ssize), pd.read_csv(test_path)\n",
    "    #return pd.read_csv(train_path), pd.read_csv(test_path)\n",
    "\n",
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training sample\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that all the missing values in 'attributed_time' are for observations that did not convert into a download ('is_attributed'=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the proportion of clicks that converted into a download or not\n",
    "plt.figure(figsize=(6,6))\n",
    "#sns.set(font_scale=1.2)\n",
    "mean = (train.is_attributed.values == 1).mean()\n",
    "ax = sns.barplot(['Converted (1)', 'Not Converted (0)'], [mean, 1-mean])\n",
    "ax.set(ylabel='Proportion', title='Proportion of clicks converted into app downloads')\n",
    "for p, uniq in zip(ax.patches, [mean, 1-mean]):\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height+0.01,\n",
    "            '{}%'.format(round(uniq * 100, 2)),\n",
    "            ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Undersampling\n",
    "Sample the data using random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate the 2 classes\n",
    "train_0 = train[train['is_attributed'] == 0]\n",
    "train_1 = train[train['is_attributed'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(train_1))\n",
    "print(train_0.shape)\n",
    "print(train.shape)\n",
    "train['is_attributed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Undersample class 0 (without replacement)\n",
    "train0_undersampled = resample(train_0, replace=False, n_samples=len(train_1), random_state=142) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine minority class with downsampled majority class\n",
    "train_us = pd.concat([train0_undersampled, train_1])\n",
    " \n",
    "# Display new class counts\n",
    "train_us.is_attributed.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract features from click_time\n",
    "def ppClicktime(df):\n",
    "    df['click_time'] = pd.to_datetime(df['click_time'])\n",
    "    df['wday'] = df['click_time'].dt.dayofweek\n",
    "    #df['week'] = df['click_time'].dt.week\n",
    "    df['hour'] = df['click_time'].dt.hour\n",
    "    #df['minute'] = df['click_time'].dt.minute\n",
    "    return df\n",
    "# Pre-process training (undersampled) and testing sets\n",
    "#train_pp = ppClicktime(train_us)\n",
    "# Pre-process training (full) and testing sets\n",
    "train_pp = ppClicktime(train)\n",
    "test_pp = ppClicktime(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop click_time\n",
    "train_pp.drop('click_time', axis = 1, inplace = True)\n",
    "test_pp.drop('click_time', axis = 1, inplace = True)\n",
    "print(len(test_pp))\n",
    "test_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "train_pp.to_csv(\"train_pp_50mil.csv\",index=None)\n",
    "#test_pp.to_csv(\"test_pp.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load in pre-processed files\n",
    "PP_PATH = r\"C:\\Users\\nguy3409\\TalkingData-master\"\n",
    "\n",
    "def load_pp(pp_path=PP_PATH):\n",
    "    # PATHS TO FILE\n",
    "    train_pp = os.path.join(pp_path, \"train_pp_50mil.csv\")\n",
    "    test_pp = os.path.join(pp_path, \"test_pp.csv\")\n",
    "    return pd.read_csv(train_pp), pd.read_csv(test_pp)\n",
    "\n",
    "train_pp, test_pp = load_pp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop attributed_time\n",
    "train_pp.drop('attributed_time', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary features\n",
    "def drop_ft(df):\n",
    "    df.drop(['week','minute'],axis=1, inplace=True)\n",
    "    return df\n",
    "train_pp = drop_ft(train_pp)\n",
    "test_pp = drop_ft(test_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def aggregate_features(df):\n",
    "    # IPs\n",
    "    n_ip = df[['ip','channel']].groupby(by=['ip'])[['channel']].count().reset_index().rename(index = str, columns={'channel': 'n_ip'})\n",
    "    df = df.merge(n_ip, on = ['ip'], how = 'left')\n",
    "    # app count\n",
    "    ip_app_count = df[['ip','app', 'channel']].groupby(by=['ip', 'app'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_app_count'})\n",
    "    df = df.merge(ip_app_count, on = ['ip', 'app'], how = 'left')\n",
    "    # device count\n",
    "    ip_device_count = df[['ip','device', 'channel']].groupby(by=['ip', 'device'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_device_count'})\n",
    "    df = df.merge(ip_device_count, on = ['ip', 'device'], how = 'left')\n",
    "    # os count\n",
    "    ip_os_count = df[['ip','os', 'channel']].groupby(by=['ip', 'os'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_os_count'})\n",
    "    df = df.merge(ip_os_count, on = ['ip', 'os'], how = 'left')\n",
    "    # wday + hour\n",
    "    ip_wday_hour = df[['ip', 'wday', 'hour', 'channel']].groupby(by = ['ip','wday','hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_wday_hour'})\n",
    "    df = df.merge(ip_wday_hour, on = ['ip', 'wday', 'hour'], how = 'left')\n",
    "    # app + hour\n",
    "    ip_app_hour = df[['ip', 'app', 'hour', 'channel']].groupby(by = ['ip','app','hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_app_hour'})\n",
    "    df = df.merge(ip_app_hour, on = ['ip', 'app', 'hour'], how = 'left')\n",
    "    # device + hour\n",
    "    ip_device_hour = df[['ip', 'device', 'hour', 'channel']].groupby(by = ['ip','device','hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_device_hour'})\n",
    "    df = df.merge(ip_device_hour, on = ['ip', 'device', 'hour'], how = 'left')\n",
    "    # os + hour\n",
    "    ip_os_hour = df[['ip', 'os', 'hour', 'channel']].groupby(by = ['ip','os','hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_os_hour'})\n",
    "    df = df.merge(ip_os_hour, on = ['ip', 'os', 'hour'], how = 'left')\n",
    "    # os + device + hour\n",
    "    ip_os_device_hour = df[['ip', 'os', 'device', 'hour', 'channel']].groupby(by = ['ip','os', 'device', 'hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_os_device_hour'})\n",
    "    df = df.merge(ip_os_device_hour, on = ['ip', 'os', 'device', 'hour'], how = 'left')\n",
    "    # app + device + hour\n",
    "    ip_app_device_hour = df[['ip', 'app', 'device', 'hour', 'channel']].groupby(by = ['ip','app', 'device', 'hour'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_app_device_hour'})\n",
    "    df = df.merge(ip_app_device_hour, on = ['ip', 'app', 'device', 'hour'], how = 'left')\n",
    "    # device + os\n",
    "    ip_os_device = df[['ip', 'os', 'device', 'channel']].groupby(by = ['ip','os', 'device'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_os_device'})\n",
    "    df = df.merge(ip_os_device, on = ['ip', 'os', 'device'], how = 'left')\n",
    "    # app + device\n",
    "    ip_app_device = df[['ip', 'app', 'device', 'channel']].groupby(by = ['ip','app', 'device'])[['channel']].count().reset_index().rename(index = str, columns = {'channel': 'ip_app_device'})\n",
    "    df = df.merge(ip_app_device, on = ['ip', 'app', 'device'], how = 'left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ag = aggregate_features(train_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ag = aggregate_features(test_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "#train_ag.to_csv(\"train_ag_50mil.csv\",index=None)\n",
    "test_ag.to_csv(\"test_ag.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load in aggregated files\n",
    "PP_PATH = r\"C:\\Users\\nguy3409\\TalkingData-master\"\n",
    "\n",
    "def load_ag(ag_path=PP_PATH):\n",
    "    # PATHS TO FILE\n",
    "    train_ag = os.path.join(ag_path, \"train_ag_50mil.csv\")\n",
    "    test_ag = os.path.join(ag_path, \"test_ag.csv\")\n",
    "    return pd.read_csv(train_ag), pd.read_csv(test_ag)\n",
    "\n",
    "train_ag, test_ag = load_ag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>wday</th>\n",
       "      <th>hour</th>\n",
       "      <th>n_ip</th>\n",
       "      <th>ip_app_count</th>\n",
       "      <th>ip_device_count</th>\n",
       "      <th>ip_os_count</th>\n",
       "      <th>ip_wday_hour</th>\n",
       "      <th>ip_app_hour</th>\n",
       "      <th>ip_device_hour</th>\n",
       "      <th>ip_os_hour</th>\n",
       "      <th>ip_os_device_hour</th>\n",
       "      <th>ip_app_device_hour</th>\n",
       "      <th>ip_os_device</th>\n",
       "      <th>ip_app_device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8126</td>\n",
       "      <td>1631</td>\n",
       "      <td>8084</td>\n",
       "      <td>2212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2199</td>\n",
       "      <td>1629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6625</td>\n",
       "      <td>1356</td>\n",
       "      <td>6540</td>\n",
       "      <td>1644</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1644</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1835</td>\n",
       "      <td>327</td>\n",
       "      <td>1573</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>40024</td>\n",
       "      <td>2310</td>\n",
       "      <td>35699</td>\n",
       "      <td>7812</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7055</td>\n",
       "      <td>2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>523</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel  wday  hour   n_ip  ip_app_count  \\\n",
       "0   83230    3       1  13      379     0    14   8126          1631   \n",
       "1   17357    3       1  19      379     0    14   6625          1356   \n",
       "2   35810    3       1  13      379     0    14   1835           327   \n",
       "3   45745   14       1  13      478     0    14  40024          2310   \n",
       "4  161007    3       1  13      379     0    14    525           104   \n",
       "\n",
       "   ip_device_count  ip_os_count  ip_wday_hour  ip_app_hour  ip_device_hour  \\\n",
       "0             8084         2212             1            1               1   \n",
       "1             6540         1644             1            1               1   \n",
       "2             1573          365             1            1               1   \n",
       "3            35699         7812             1            1               1   \n",
       "4              523          114             1            1               1   \n",
       "\n",
       "   ip_os_hour  ip_os_device_hour  ip_app_device_hour  ip_os_device  \\\n",
       "0           1                  1                   1          2199   \n",
       "1           1                  1                   1          1644   \n",
       "2           1                  1                   1           300   \n",
       "3           1                  1                   1          7055   \n",
       "4           1                  1                   1           114   \n",
       "\n",
       "   ip_app_device  \n",
       "0           1629  \n",
       "1           1354  \n",
       "2            275  \n",
       "3           2260  \n",
       "4            104  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate response variables from predictors\n",
    "y = list(train_ag.is_attributed)\n",
    "X = train_ag.drop(['is_attributed'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop ip\n",
    "X = X.drop(['ip'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the training data into training and test sets for cross-validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "# Predict on test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_prob = logreg.predict_proba(X_test)\n",
    "# AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "Ntree = 500\n",
    "rfc = RandomForestClassifier(n_estimators=Ntree)\n",
    "rfc.fit(X_train, y_train)\n",
    "# Predict on test set\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_pred_prob = rfc.predict_proba(X_test)\n",
    "# AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = 'is_attributed'\n",
    "predictors = ['device', 'app', 'os', 'channel', 'wday', 'hour',\n",
    "              'n_ip', 'ip_app_count', 'ip_device_count', 'ip_os_count',\n",
    "              'ip_wday_hour', 'ip_app_hour', 'ip_device_hour', \n",
    "              'ip_os_hour', 'ip_os_device_hour']\n",
    "categorical = ['app', 'device', 'os', 'channel', 'wday', 'hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 255,  \n",
    "    'max_depth': 8,  \n",
    "    'min_child_samples': 100,  \n",
    "    'max_bin': 100,  \n",
    "    'subsample': 0.7,  \n",
    "    'subsample_freq': 1,  \n",
    "    'colsample_bytree': 0.7,  \n",
    "    'min_child_weight': 0,  \n",
    "    'subsample_for_bin': 200000,  \n",
    "    'min_split_gain': 0,  \n",
    "    'reg_alpha': 0,  \n",
    "    'reg_lambda': 0,  \n",
    "   # 'nthread': 8,\n",
    "    'verbose': 0,\n",
    "    'scale_pos_weight': 99.7\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X_train[predictors].values, label=y_train,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "dvalid = lgb.Dataset(X_test.values, label=y_test,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's auc: 0.959651\tvalid's auc: 0.942052\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[2]\ttrain's auc: 0.963331\tvalid's auc: 0.928831\n",
      "[3]\ttrain's auc: 0.967055\tvalid's auc: 0.931711\n",
      "[4]\ttrain's auc: 0.968529\tvalid's auc: 0.933303\n",
      "[5]\ttrain's auc: 0.969338\tvalid's auc: 0.942857\n",
      "[6]\ttrain's auc: 0.969776\tvalid's auc: 0.946971\n",
      "[7]\ttrain's auc: 0.970897\tvalid's auc: 0.947145\n",
      "[8]\ttrain's auc: 0.971453\tvalid's auc: 0.947572\n",
      "[9]\ttrain's auc: 0.971779\tvalid's auc: 0.948006\n",
      "[10]\ttrain's auc: 0.971768\tvalid's auc: 0.950314\n",
      "[11]\ttrain's auc: 0.972249\tvalid's auc: 0.947376\n",
      "[12]\ttrain's auc: 0.972521\tvalid's auc: 0.947726\n",
      "[13]\ttrain's auc: 0.972932\tvalid's auc: 0.950185\n",
      "[14]\ttrain's auc: 0.973214\tvalid's auc: 0.950613\n",
      "[15]\ttrain's auc: 0.97347\tvalid's auc: 0.95106\n",
      "[16]\ttrain's auc: 0.973724\tvalid's auc: 0.951309\n",
      "[17]\ttrain's auc: 0.973902\tvalid's auc: 0.947925\n",
      "[18]\ttrain's auc: 0.974093\tvalid's auc: 0.948491\n",
      "[19]\ttrain's auc: 0.974169\tvalid's auc: 0.948873\n",
      "[20]\ttrain's auc: 0.974403\tvalid's auc: 0.951923\n",
      "[21]\ttrain's auc: 0.974486\tvalid's auc: 0.952099\n",
      "[22]\ttrain's auc: 0.974479\tvalid's auc: 0.952061\n",
      "[23]\ttrain's auc: 0.974734\tvalid's auc: 0.952334\n",
      "[24]\ttrain's auc: 0.974956\tvalid's auc: 0.954795\n",
      "[25]\ttrain's auc: 0.975065\tvalid's auc: 0.954692\n",
      "[26]\ttrain's auc: 0.975333\tvalid's auc: 0.955431\n",
      "[27]\ttrain's auc: 0.975416\tvalid's auc: 0.955431\n",
      "[28]\ttrain's auc: 0.975607\tvalid's auc: 0.955781\n",
      "[29]\ttrain's auc: 0.975825\tvalid's auc: 0.957617\n",
      "[30]\ttrain's auc: 0.975946\tvalid's auc: 0.957595\n",
      "[31]\ttrain's auc: 0.976335\tvalid's auc: 0.958773\n",
      "[32]\ttrain's auc: 0.976564\tvalid's auc: 0.960112\n",
      "[33]\ttrain's auc: 0.976789\tvalid's auc: 0.960351\n",
      "[34]\ttrain's auc: 0.976983\tvalid's auc: 0.960417\n",
      "[35]\ttrain's auc: 0.977196\tvalid's auc: 0.960623\n",
      "[36]\ttrain's auc: 0.977369\tvalid's auc: 0.960698\n",
      "[37]\ttrain's auc: 0.97753\tvalid's auc: 0.960953\n",
      "[38]\ttrain's auc: 0.977693\tvalid's auc: 0.960923\n",
      "[39]\ttrain's auc: 0.97793\tvalid's auc: 0.961869\n",
      "[40]\ttrain's auc: 0.97802\tvalid's auc: 0.962102\n",
      "[41]\ttrain's auc: 0.978169\tvalid's auc: 0.961894\n",
      "[42]\ttrain's auc: 0.978275\tvalid's auc: 0.961735\n",
      "[43]\ttrain's auc: 0.978575\tvalid's auc: 0.96237\n",
      "[44]\ttrain's auc: 0.97878\tvalid's auc: 0.962319\n",
      "[45]\ttrain's auc: 0.978969\tvalid's auc: 0.962605\n",
      "[46]\ttrain's auc: 0.979135\tvalid's auc: 0.962244\n",
      "[47]\ttrain's auc: 0.979329\tvalid's auc: 0.961935\n",
      "[48]\ttrain's auc: 0.979549\tvalid's auc: 0.962113\n",
      "[49]\ttrain's auc: 0.979639\tvalid's auc: 0.961827\n",
      "[50]\ttrain's auc: 0.979738\tvalid's auc: 0.961616\n",
      "[51]\ttrain's auc: 0.979907\tvalid's auc: 0.96136\n",
      "[52]\ttrain's auc: 0.980104\tvalid's auc: 0.961799\n",
      "[53]\ttrain's auc: 0.980217\tvalid's auc: 0.961575\n",
      "[54]\ttrain's auc: 0.980294\tvalid's auc: 0.961282\n",
      "[55]\ttrain's auc: 0.980433\tvalid's auc: 0.961267\n",
      "[56]\ttrain's auc: 0.980573\tvalid's auc: 0.960948\n",
      "[57]\ttrain's auc: 0.980723\tvalid's auc: 0.960726\n",
      "[58]\ttrain's auc: 0.980849\tvalid's auc: 0.960465\n",
      "[59]\ttrain's auc: 0.980938\tvalid's auc: 0.959684\n",
      "[60]\ttrain's auc: 0.981147\tvalid's auc: 0.959914\n",
      "[61]\ttrain's auc: 0.981262\tvalid's auc: 0.959973\n",
      "[62]\ttrain's auc: 0.981451\tvalid's auc: 0.960131\n",
      "[63]\ttrain's auc: 0.981564\tvalid's auc: 0.960314\n",
      "[64]\ttrain's auc: 0.981668\tvalid's auc: 0.960501\n",
      "[65]\ttrain's auc: 0.98175\tvalid's auc: 0.960469\n",
      "[66]\ttrain's auc: 0.981833\tvalid's auc: 0.96026\n",
      "[67]\ttrain's auc: 0.981882\tvalid's auc: 0.959967\n",
      "[68]\ttrain's auc: 0.981953\tvalid's auc: 0.960065\n",
      "[69]\ttrain's auc: 0.982118\tvalid's auc: 0.960074\n",
      "[70]\ttrain's auc: 0.982254\tvalid's auc: 0.959938\n",
      "[71]\ttrain's auc: 0.982326\tvalid's auc: 0.959443\n",
      "[72]\ttrain's auc: 0.982463\tvalid's auc: 0.959146\n",
      "[73]\ttrain's auc: 0.982579\tvalid's auc: 0.959109\n",
      "[74]\ttrain's auc: 0.982681\tvalid's auc: 0.958697\n",
      "[75]\ttrain's auc: 0.9828\tvalid's auc: 0.958684\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttrain's auc: 0.978969\tvalid's auc: 0.962605\n"
     ]
    }
   ],
   "source": [
    "evals_results = {}\n",
    "lgb_model = lgb.train(params, \n",
    "                 dtrain, \n",
    "                 valid_sets=[dtrain, dvalid], \n",
    "                 valid_names=['train','valid'], \n",
    "                 evals_result=evals_results, \n",
    "                 num_boost_round=350,\n",
    "                 early_stopping_rounds=30,\n",
    "                 verbose_eval=True, \n",
    "                 feval=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'is_attributed'\n",
    "predictors = ['device', 'app', 'os', 'channel', 'wday', 'hour',\n",
    "              'n_ip', 'ip_app_count', 'ip_device_count', 'ip_os_count',\n",
    "              'ip_wday_hour', 'ip_app_hour', 'ip_device_hour', \n",
    "              'ip_os_hour', 'ip_os_device_hour', 'ip_app_device_hour',\n",
    "              'ip_os_device', 'ip_app_device']\n",
    "categorical = ['app', 'device', 'os', 'channel', 'wday', 'hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'eta': 0.3,\n",
    "          'tree_method': \"hist\",\n",
    "          'grow_policy': \"lossguide\",\n",
    "          'max_leaves': 1400,  \n",
    "          'max_depth': 0, \n",
    "          'subsample': 0.9, \n",
    "          'colsample_bytree': 0.7, \n",
    "          'colsample_bylevel':0.7,\n",
    "          'min_child_weight':0,\n",
    "          'alpha':4,\n",
    "          'objective': 'binary:logistic', \n",
    "          'scale_pos_weight':9,\n",
    "          'eval_metric': 'auc', \n",
    "          'nthread':8,\n",
    "          'random_state': 99, \n",
    "          'silent': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X_train[predictors].values, label=y_train,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "dvalid = lgb.Dataset(X_test.values, label=y_test,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-60f47eb5ca90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m xgb_model = xgb.train(params, \n\u001b[0m\u001b[0;32m      2\u001b[0m                       \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                       \u001b[0mwatchlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                       \u001b[0mmaximize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                       \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.train(params, \n",
    "                      dtrain, 200, \n",
    "                      watchlist = [(dtrain, 'train'), (dvalid, 'valid')], \n",
    "                      maximize=True, \n",
    "                      early_stopping_rounds = 30, \n",
    "                      verbose_eval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on test dataset and write out submission file\n",
    "test2 = test_ag.drop(['click_id','ip'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_submit = logreg.predict(test2)\n",
    "#y_submit = rfc.predict(test2)\n",
    "y_submit = lgb_model.predict(test2[predictors],num_iteration=lgb_model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ag['is_attributed'] = y_submit\n",
    "ans = test_ag[['click_id', 'is_attributed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the feature importance from lgb\n",
    "plot_importance(lgb_model)\n",
    "plt.gcf().savefig('feature_importance_lgb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
